{
  "biasnb/biasedmodel.ipynb": {
    "metadata": {
      "notebook_path": "biasnb/biasedmodel.ipynb",
      "timestamp": "2024-12-05T11:49:28.818150",
      "bias_threshold": 0.05
    },
    "summary": {
      "total_cells": 2,
      "reproducible_cells": 2,
      "non_reproducible_cells": 1,
      "random_cells": 2,
      "reproducible_random_cells": 2,
      "non_reproducible_random_cells": 0,
      "no_output_cells": 0
    },
    "non_reproducible_details": {
      "execution_errors": [],
      "output_mismatches": [],
      "missing_expected_outputs": [],
      "unexpected_new_outputs": [],
      "failed_random_cells": [],
      "model_bias_variations": [
        {
          "cell_number": 2,
          "bias_details": {
            "original_bias": 0.6000000000000001,
            "retrained_bias": 0.74,
            "bias_difference": 0.1399999999999999,
            "threshold": 0.05
          }
        }
      ]
    },
    "library_analysis": {
      "installed": [],
      "required": [
        "numpy",
        "scikit-learn",
        "pandas",
        "collections"
      ],
      "missing": [
        "numpy",
        "scikit-learn",
        "pandas",
        "collections"
      ]
    },
    "cell_results": [
      {
        "cell_number": 1,
        "reproducible": true,
        "is_random": true,
        "source": "# Create an imbalanced dataset with correlated features\ndef create_dataset(n_samples=1000):\n    X_majority = np.random.normal(0.7, 0.3, (int(0.8 * n_samples), 5))\n    y_majority = np.zeros(int(0.8 * n_samples))\n    \n    X_minority = np.random.normal(0.3, 0.3, (int(0.2 * n_samples), 5))\n    y_minority = np.ones(int(0.2 * n_samples))\n    \n    X = np.vstack([X_majority, X_minority])\n    y = np.hstack([y_majority, y_minority])\n    \n    # Add random noise\n    X += np.random.normal(0, 0.2, X.shape)\n    \n    feature_names = ['income', 'education', 'age', 'experience', 'skill_level']\n    X = pd.DataFrame(X, columns=feature_names)\n    \n    return X, y\n\nX, y = create_dataset()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Display class distribution (will be different each run)\ndistribution = pd.Series(y_train).value_counts()\ndistribution",
        "had_original_output": true,
        "random_execution_successful": true
      },
      {
        "cell_number": 2,
        "reproducible": true,
        "is_random": true,
        "source": "# Train initial model with random undersampling\nminority_indices = np.where(y_train == 1)[0]\nmajority_indices = np.where(y_train == 0)[0]\nsampled_majority = np.random.choice(majority_indices, size=len(minority_indices) * 2, replace=False)\n\n# majority size == minority size\nbalanced_indices = np.concatenate([minority_indices, sampled_majority])\nX_balanced = X_train.iloc[balanced_indices]\ny_balanced = y_train[balanced_indices]\n\n# Using a small number of trees and limited depth for more variance\nmodel = RandomForestClassifier(n_estimators=20, max_depth=3)\nmodel.fit(X_balanced, y_balanced)\n\n# Get predictions and probabilities\npredictions = model.predict(X_test)\nprobabilities = model.predict_proba(X_test)\n\n# Store results as cell output\ninitial_results = {\n    'accuracy': accuracy_score(y_test, predictions),\n    'mean_prob_class0': probabilities[:, 0].mean(),\n    'mean_prob_class1': probabilities[:, 1].mean(),\n    'predictions_distribution': pd.Series(predictions).value_counts().to_dict()\n}\ninitial_results",
        "had_original_output": true,
        "random_execution_successful": true
      }
    ],
    "ml_analysis": {
      "models": {
        "model_2": {
          "cell_number": 2,
          "variable_name": "model",
          "original_bias": 0.6000000000000001,
          "model_type": "RandomForestClassifier",
          "parameters": {
            "bootstrap": true,
            "ccp_alpha": 0.0,
            "class_weight": null,
            "criterion": "gini",
            "max_depth": 3,
            "max_features": "sqrt",
            "max_leaf_nodes": null,
            "max_samples": null,
            "min_impurity_decrease": 0.0,
            "min_samples_leaf": 1,
            "min_samples_split": 2,
            "min_weight_fraction_leaf": 0.0,
            "monotonic_cst": null,
            "n_estimators": 20,
            "n_jobs": null,
            "oob_score": false,
            "random_state": null,
            "verbose": 0,
            "warm_start": false
          },
          "retrained_bias": 0.74,
          "bias_difference": 0.1399999999999999,
          "lime_analysis": {
            "original_explanation": [
              [
                "skill_level > 0.86",
                -0.142735509992094
              ],
              [
                "education > 0.88",
                -0.0910749951500576
              ],
              [
                "0.39 < age <= 0.68",
                -0.041769428869808806
              ],
              [
                "0.61 < income <= 0.92",
                -0.03557040394707382
              ],
              [
                "0.36 < experience <= 0.64",
                -0.024533002557723598
              ]
            ],
            "retrained_explanation": [
              [
                "skill_level > 0.86",
                -0.11073551491980799
              ],
              [
                "0.61 < income <= 0.92",
                -0.052610630492362344
              ],
              [
                "education > 0.88",
                -0.05049143297052486
              ],
              [
                "0.39 < age <= 0.68",
                -0.0415536026759267
              ],
              [
                "0.36 < experience <= 0.64",
                -0.023610522583678354
              ]
            ],
            "feature_importance_differences": {
              "0.61 < income <= 0.92": {
                "original_importance": -0.03557040394707382,
                "retrained_importance": -0.052610630492362344,
                "absolute_difference": 0.01704022654528852
              },
              "skill_level > 0.86": {
                "original_importance": -0.142735509992094,
                "retrained_importance": -0.11073551491980799,
                "absolute_difference": 0.031999995072286014
              },
              "education > 0.88": {
                "original_importance": -0.0910749951500576,
                "retrained_importance": -0.05049143297052486,
                "absolute_difference": 0.04058356217953274
              }
            }
          }
        }
      }
    }
  }
}